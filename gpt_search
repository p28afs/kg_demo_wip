from langchain.chat_models import ChatOpenAI
from langchain.prompts.chat import ChatPromptTemplate, HumanMessagePromptTemplate

def main():
    # Define the question variable
    question = "What is the capital of France?"
    
    # Create a ChatPromptTemplate using a HumanMessagePromptTemplate
    prompt = ChatPromptTemplate.from_messages([
        HumanMessagePromptTemplate.from_template("Please answer the following question: {question}")
    ])
    
    # Format the prompt by injecting the question variable
    messages = prompt.format_messages(question=question)
    
    # Initialize the ChatOpenAI instance
    chat = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)
    
    # Ask the question and capture the response
    response = chat(messages)
    
    # Print the answer from the model
    print("Response:")
    print(response.content)

if __name__ == "__main__":
    main()
